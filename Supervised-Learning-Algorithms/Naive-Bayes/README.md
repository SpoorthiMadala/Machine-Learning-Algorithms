# Naive Bayes Variants

This project covers implementations of the main Naive Bayes classifiers used for classification tasks:

- **Gaussian Naive Bayes:** Suitable for continuous data with normally distributed features.
- **Multinomial Naive Bayes:** Used for discrete count data, commonly applied in text classification.
- **Bernoulli Naive Bayes:** Designed for binary/boolean features.

Each variant is demonstrated with a relevant dataset, including data preprocessing, model training, evaluation, and performance metrics.

---

## Table of Contents

- [Gaussian Naive Bayes](#gaussian-naive-bayes)
- [Multinomial Naive Bayes](#multinomial-naive-bayes)
- [Bernoulli Naive Bayes](#bernoulli-naive-bayes)

---

## Gaussian Naive Bayes

Gaussian Naive Bayes assumes features follow a normal distribution. It is commonly used with continuous features.

---

## Multinomial Naive Bayes

Multinomial Naive Bayes works well with discrete features such as word counts in text classification problems.

---

## Bernoulli Naive Bayes

Bernoulli Naive Bayes is suitable for binary/boolean feature vectors, e.g., presence or absence of words.

---

## Usage

Each variant is implemented in separate Python scripts or notebooks, demonstrating model training, prediction, and evaluation.

---

## Evaluation Metrics

- Accuracy
- Classification Report (Precision, Recall, F1-Score)
- Confusion Matrix
